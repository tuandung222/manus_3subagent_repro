{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f613f06f",
   "metadata": {},
   "source": [
    "# Tutorial: Implement Agent Orchestration Loop in Notebook\n",
    "\n",
    "Goals:\n",
    "- Implement a manual orchestration loop directly in notebook cells.\n",
    "- Compare manual-loop behavior against the production LangGraph workflow.\n",
    "- Observe `continue/replan/end` transitions under both CodeAct and ReAct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56db57eb",
   "metadata": {},
   "source": [
    "## Outline\n",
    "1. Setup runtime components.\n",
    "2. Manual orchestration loop (educational version).\n",
    "3. Official LangGraph workflow run.\n",
    "4. Compare outcomes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58438dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    for candidate in [start, *start.parents]:\n",
    "        if (candidate / \"pyproject.toml\").exists() and (candidate / \"src\").exists():\n",
    "            return candidate\n",
    "    raise RuntimeError(\"Could not locate repo root\")\n",
    "\n",
    "\n",
    "REPO_ROOT = find_repo_root(Path.cwd())\n",
    "if str(REPO_ROOT / \"src\") not in sys.path:\n",
    "    sys.path.insert(0, str(REPO_ROOT / \"src\"))\n",
    "\n",
    "from manus_three_agent.agents import ArchitectAgent, CriticAgent, WorkerAgent\n",
    "from manus_three_agent.core.schemas import PlanStep\n",
    "from manus_three_agent.core.state import build_initial_state\n",
    "from manus_three_agent.core.types import ModelConfig\n",
    "from manus_three_agent.environments.simulator import GenericSimulatorEnvironment\n",
    "from manus_three_agent.graph import build_workflow\n",
    "from manus_three_agent.prompts import PromptTemplates\n",
    "from manus_three_agent.tools import build_default_tool_registry\n",
    "from manus_three_agent.tracing import TraceCollector\n",
    "\n",
    "prompts = PromptTemplates(config_dir=str(REPO_ROOT / \"configs\" / \"prompts\"))\n",
    "model_cfg = ModelConfig(model=\"mock\")\n",
    "tracer = TraceCollector.disabled()\n",
    "tools = build_default_tool_registry()\n",
    "\n",
    "print(f\"Repo root: {REPO_ROOT}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9168c5db",
   "metadata": {},
   "source": [
    "## Step 1: Manual orchestration loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648dbb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_manual_loop(goal: str, agentic_mode: str = \"codeact\", max_steps: int = 6):\n",
    "    env = GenericSimulatorEnvironment()\n",
    "    architect = ArchitectAgent(model_cfg, prompts, tracer=tracer, force_mock=True, agentic_mode=agentic_mode)\n",
    "    worker = WorkerAgent(model_cfg, prompts, tools, tracer=tracer, force_mock=True, agentic_mode=agentic_mode)\n",
    "    verifier = CriticAgent(model_cfg, prompts, tracer=tracer, force_mock=True, agentic_mode=agentic_mode)\n",
    "\n",
    "    state = build_initial_state(\n",
    "        goal=goal,\n",
    "        observation=env.reset(goal=goal),\n",
    "        max_steps=max_steps,\n",
    "        dynamic_replanning=True,\n",
    "        use_cot=False,\n",
    "        agentic_mode=agentic_mode,\n",
    "    )\n",
    "\n",
    "    timeline = []\n",
    "\n",
    "    while not state[\"done\"] and state[\"step_count\"] < state[\"max_steps\"]:\n",
    "        if not state[\"plan\"] or state[\"current_step_idx\"] >= len(state[\"plan\"]):\n",
    "            plan_out = architect.plan(\n",
    "                goal=state[\"goal\"],\n",
    "                observation=state[\"observation\"],\n",
    "                action_history=state[\"action_history\"],\n",
    "                use_cot=state[\"use_cot\"],\n",
    "                step=state[\"step_count\"],\n",
    "            )\n",
    "            state[\"plan\"] = [s.model_dump() for s in plan_out.steps]\n",
    "            state[\"current_step_idx\"] = 0\n",
    "            timeline.append({\"phase\": \"planner\", \"step\": state[\"step_count\"], \"plan_len\": len(state[\"plan\"])})\n",
    "\n",
    "        current_step = PlanStep.model_validate(state[\"plan\"][state[\"current_step_idx\"]])\n",
    "        action = worker.execute(\n",
    "            goal=state[\"goal\"],\n",
    "            plan_step=current_step,\n",
    "            observation=state[\"observation\"],\n",
    "            step_index=state[\"current_step_idx\"],\n",
    "            total_steps=len(state[\"plan\"]),\n",
    "            use_cot=state[\"use_cot\"],\n",
    "            step=state[\"step_count\"],\n",
    "        )\n",
    "\n",
    "        env_result = env.step(action=action, step_count=state[\"step_count\"] + 1)\n",
    "        state[\"action_history\"].append(action.model_dump())\n",
    "        state[\"observation\"] = env_result.observation\n",
    "        state[\"step_count\"] += 1\n",
    "        state[\"current_step_idx\"] += 1\n",
    "\n",
    "        if action.is_final or env_result.done:\n",
    "            state[\"done\"] = True\n",
    "            state[\"success\"] = True\n",
    "            state[\"final_answer\"] = action.final_answer or env_result.final_answer\n",
    "\n",
    "        review = verifier.review(\n",
    "            goal=state[\"goal\"],\n",
    "            observation=state[\"observation\"],\n",
    "            action_history=state[\"action_history\"],\n",
    "            current_step_idx=state[\"current_step_idx\"],\n",
    "            plan_length=len(state[\"plan\"]),\n",
    "            step=state[\"step_count\"],\n",
    "        )\n",
    "        state[\"review_history\"].append(review.model_dump())\n",
    "        state[\"decision\"] = review.decision\n",
    "\n",
    "        timeline.append({\n",
    "            \"phase\": \"worker+verifier\",\n",
    "            \"step\": state[\"step_count\"],\n",
    "            \"action_summary\": action.summary,\n",
    "            \"decision\": review.decision,\n",
    "        })\n",
    "\n",
    "        if state[\"done\"]:\n",
    "            break\n",
    "        if review.decision == \"replan\":\n",
    "            state[\"plan\"] = []\n",
    "            state[\"current_step_idx\"] = 0\n",
    "        elif review.decision == \"end\":\n",
    "            state[\"done\"] = True\n",
    "            state[\"success\"] = state[\"success\"] or review.should_succeed\n",
    "            if not state[\"final_answer\"]:\n",
    "                state[\"final_answer\"] = \"Verifier ended run.\"\n",
    "\n",
    "    return state, timeline\n",
    "\n",
    "\n",
    "goal = \"Build a compact long-horizon agent evaluation routine\"\n",
    "manual_results = {}\n",
    "for mode in [\"codeact\", \"react\"]:\n",
    "    final_state, timeline = run_manual_loop(goal=goal, agentic_mode=mode)\n",
    "    manual_results[mode] = {\n",
    "        \"summary\": {\n",
    "            \"success\": final_state[\"success\"],\n",
    "            \"step_count\": final_state[\"step_count\"],\n",
    "            \"decision\": final_state[\"decision\"],\n",
    "            \"final_answer\": final_state[\"final_answer\"],\n",
    "        },\n",
    "        \"timeline\": timeline,\n",
    "    }\n",
    "\n",
    "print(json.dumps(manual_results, indent=2, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaea6415",
   "metadata": {},
   "source": [
    "## Step 2: Run official LangGraph workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3eb467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_graph_workflow(goal: str, agentic_mode: str = \"codeact\"):\n",
    "    env = GenericSimulatorEnvironment()\n",
    "    architect = ArchitectAgent(model_cfg, prompts, tracer=tracer, force_mock=True, agentic_mode=agentic_mode)\n",
    "    worker = WorkerAgent(model_cfg, prompts, tools, tracer=tracer, force_mock=True, agentic_mode=agentic_mode)\n",
    "    verifier = CriticAgent(model_cfg, prompts, tracer=tracer, force_mock=True, agentic_mode=agentic_mode)\n",
    "\n",
    "    workflow = build_workflow(architect, worker, verifier, env, tracer)\n",
    "    initial_state = build_initial_state(\n",
    "        goal=goal,\n",
    "        observation=env.reset(goal=goal),\n",
    "        max_steps=6,\n",
    "        dynamic_replanning=True,\n",
    "        use_cot=False,\n",
    "        agentic_mode=agentic_mode,\n",
    "    )\n",
    "    return workflow.invoke(initial_state)\n",
    "\n",
    "graph_results = {}\n",
    "for mode in [\"codeact\", \"react\"]:\n",
    "    out = run_graph_workflow(goal=goal, agentic_mode=mode)\n",
    "    graph_results[mode] = {\n",
    "        \"success\": out[\"success\"],\n",
    "        \"step_count\": out[\"step_count\"],\n",
    "        \"final_answer\": out[\"final_answer\"],\n",
    "        \"decision\": out[\"decision\"],\n",
    "    }\n",
    "\n",
    "print(json.dumps(graph_results, indent=2, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d810b69",
   "metadata": {},
   "source": [
    "## Step 3: Compare manual loop vs graph output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d743be",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = {}\n",
    "for mode in [\"codeact\", \"react\"]:\n",
    "    comparison[mode] = {\n",
    "        \"manual_step_count\": manual_results[mode][\"summary\"][\"step_count\"],\n",
    "        \"graph_step_count\": graph_results[mode][\"step_count\"],\n",
    "        \"manual_success\": manual_results[mode][\"summary\"][\"success\"],\n",
    "        \"graph_success\": graph_results[mode][\"success\"],\n",
    "    }\n",
    "\n",
    "print(json.dumps(comparison, indent=2, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a288c34",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "- The manual loop helps architects reason about transition logic before optimization.\n",
    "- The graph workflow is the production runtime path and should keep deterministic routing.\n",
    "- Tracing can be attached to both manual and graph flows for trajectory-quality comparison."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
